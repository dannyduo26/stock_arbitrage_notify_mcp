import os
import sys
import json
import asyncio
import logging
from typing import List, Dict, Any
from openai import OpenAI
from mcp import ClientSession
from mcp.client.sse import sse_client

# æ·»åŠ çˆ¶ç›®å½•åˆ°ç³»ç»Ÿè·¯å¾„ï¼Œä»¥ä¾¿å¯¼å…¥ config æ¨¡å—
sys.path.insert(0, os.path.join(os.path.dirname(__file__), '..'))

# é…ç½®æ—¥å¿—
from config.logging_config import setup_logging
logger = setup_logging()

# åŠ è½½é…ç½®
# è·å–é¡¹ç›®æ ¹ç›®å½•
ROOT_DIR = os.path.dirname(os.path.dirname(os.path.abspath(__file__)))
config_path = os.path.join(ROOT_DIR, "config.json")

try:
    with open(config_path, "r", encoding="utf-8") as f:
        config = json.load(f)
except FileNotFoundError:
    logger.error(f"âŒ é…ç½®æ–‡ä»¶æœªæ‰¾åˆ°: {config_path}")
    logger.error("è¯·ç¡®ä¿ä»é¡¹ç›®æ ¹ç›®å½•è¿è¡Œè„šæœ¬ï¼Œæˆ– config.json æ–‡ä»¶å­˜åœ¨")
    sys.exit(1)

# ä½¿ç”¨ DeepSeek é…ç½®
client = OpenAI(
    api_key=config["deepseek_api_key"],
    base_url=config["deepseek_base_url"]
)

# MCP æœåŠ¡å™¨åœ°å€
# MCP_SERVER_URL = os.getenv("MCP_SERVER_URL", "http://127.0.0.1:4567/sse")
MCP_SERVER_URL = os.getenv("MCP_SERVER_URL", "http://175.24.206.252:4567/sse")



async def get_available_tools() -> List[Dict[str, Any]]:
    """
    è·å– MCP æœåŠ¡å™¨æä¾›çš„æ‰€æœ‰å¯ç”¨å·¥å…·
    
    Returns:
        å·¥å…·åˆ—è¡¨ï¼Œæ¯ä¸ªå·¥å…·åŒ…å« name, description, inputSchema
    """
    async with sse_client(MCP_SERVER_URL) as (read_stream, write_stream):
        async with ClientSession(read_stream, write_stream) as session:
            # åˆå§‹åŒ–ä¼šè¯
            await session.initialize()
            
            # åˆ—å‡ºæ‰€æœ‰å·¥å…·
            tools_list = await session.list_tools()
            
            # è½¬æ¢ä¸ºå­—å…¸åˆ—è¡¨
            tools = []
            for tool in tools_list.tools:
                tools.append({
                    "name": tool.name,
                    "description": tool.description,
                    "inputSchema": tool.inputSchema
                })
            
            return tools


async def call_mcp_tool(tool_name: str, arguments: dict = None):
    """
    è°ƒç”¨ MCP å·¥å…·
    
    Args:
        tool_name: å·¥å…·åç§°
        arguments: å·¥å…·å‚æ•°
        
    Returns:
        å·¥å…·è°ƒç”¨ç»“æœ
    """
    async with sse_client(MCP_SERVER_URL) as (read_stream, write_stream):
        async with ClientSession(read_stream, write_stream) as session:
            # åˆå§‹åŒ–ä¼šè¯
            await session.initialize()
            
            # è°ƒç”¨å·¥å…·
            result = await session.call_tool(tool_name, arguments=arguments or {})
            
            # è§£æç»“æœ
            if result.content:
                return json.loads(result.content[0].text)
            return None


def format_tools_for_llm(tools: List[Dict[str, Any]]) -> str:
    """
    å°†å·¥å…·åˆ—è¡¨æ ¼å¼åŒ–ä¸ºé€‚åˆ LLM ç†è§£çš„æ–‡æœ¬
    
    Args:
        tools: å·¥å…·åˆ—è¡¨
        
    Returns:
        æ ¼å¼åŒ–åçš„å·¥å…·æè¿°æ–‡æœ¬
    """
    formatted = "å¯ç”¨çš„ MCP å·¥å…·åˆ—è¡¨:\n\n"
    for i, tool in enumerate(tools, 1):
        formatted += f"{i}. å·¥å…·åç§°: {tool['name']}\n"
        formatted += f"   æè¿°: {tool['description']}\n"
        formatted += f"   å‚æ•°: {json.dumps(tool['inputSchema'], ensure_ascii=False, indent=2)}\n\n"
    return formatted


def ask_deepseek_with_tools(user_query: str, tools_info: str, conversation_history: List[Dict] = None) -> Dict[str, Any]:
    """
    ä½¿ç”¨ DeepSeek API ç”Ÿæˆå›å¤ï¼Œæ”¯æŒå·¥å…·è°ƒç”¨
    
    Args:
        user_query: ç”¨æˆ·æŸ¥è¯¢
        tools_info: å·¥å…·ä¿¡æ¯
        conversation_history: å¯¹è¯å†å²
        
    Returns:
        åŒ…å« actionï¼ˆ"tool_call" æˆ– "final_answer"ï¼‰ã€tool_nameã€arguments æˆ– answer çš„å­—å…¸
    """
    system_prompt = f"""ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„é‡‘èåˆ†æåŠ©æ‰‹,èƒ½å¤Ÿä½¿ç”¨æä¾›çš„ MCP å·¥å…·æ¥è·å–æ•°æ®å¹¶è¿›è¡Œåˆ†æã€‚

{tools_info}

**é‡è¦è§„åˆ™:**
1. ä½ å¿…é¡»å®Œæˆç”¨æˆ·è¦æ±‚çš„æ‰€æœ‰ä»»åŠ¡æ­¥éª¤,ä¸èƒ½é—æ¼ä»»ä½•ä¸€ä¸ª
2. å¦‚æœç”¨æˆ·è¦æ±‚å‘é€é€šçŸ¥,ä½ å¿…é¡»åœ¨å®Œæˆæ•°æ®åˆ†æåè°ƒç”¨ send_wechat å·¥å…·
3. åªæœ‰åœ¨å®Œæˆæ‰€æœ‰ä»»åŠ¡æ­¥éª¤å,æ‰èƒ½è¿”å› final_answer
4. æ¯æ¬¡åªèƒ½è°ƒç”¨ä¸€ä¸ªå·¥å…·,å¤šä¸ªä»»åŠ¡éœ€è¦åˆ†å¤šè½®å®Œæˆ

**å·¥ä½œæµç¨‹:**
- ç¬¬ä¸€æ­¥:åˆ†æç”¨æˆ·éœ€æ±‚,åˆ—å‡ºéœ€è¦å®Œæˆçš„æ‰€æœ‰ä»»åŠ¡æ­¥éª¤
- ç¬¬äºŒæ­¥:æŒ‰é¡ºåºæ‰§è¡Œæ¯ä¸ªæ­¥éª¤,æ¯æ¬¡è°ƒç”¨ä¸€ä¸ªå·¥å…·
- ç¬¬ä¸‰æ­¥:ç¡®è®¤æ‰€æœ‰æ­¥éª¤éƒ½å·²å®Œæˆå,å†ç»™å‡ºæœ€ç»ˆç­”æ¡ˆ

**è¿”å›æ ¼å¼:**
- å¦‚æœéœ€è¦è°ƒç”¨å·¥å…·:
{{
  "action": "tool_call",
  "tool_name": "å·¥å…·åç§°",
  "arguments": {{"å‚æ•°å": "å‚æ•°å€¼"}},
  "reason": "ä¸ºä»€ä¹ˆé€‰æ‹©è¿™ä¸ªå·¥å…·å’Œå‚æ•°"
}}

- å¦‚æœæ‰€æœ‰ä»»åŠ¡æ­¥éª¤éƒ½å·²å®Œæˆ,å¯ä»¥ç»™å‡ºæœ€ç»ˆç­”æ¡ˆ:
{{
  "action": "final_answer",
  "answer": "ä½ çš„åˆ†ææŠ¥å‘Šæˆ–å›ç­”"
}}

è¯·åªè¿”å› JSON,ä¸è¦åŒ…å«å…¶ä»–æ–‡å­—ã€‚"""

    messages = [{"role": "system", "content": system_prompt}]
    
    # æ·»åŠ å¯¹è¯å†å²
    if conversation_history:
        messages.extend(conversation_history)
    
    # æ·»åŠ ç”¨æˆ·æŸ¥è¯¢
    messages.append({"role": "user", "content": user_query})
    
    resp = client.chat.completions.create(
        model="deepseek-chat",
        messages=messages,
        max_tokens=1000,
        temperature=0.7,
    )
    
    content = resp.choices[0].message.content.strip()
    
    # å°è¯•è§£æ JSON
    try:
        # ç§»é™¤å¯èƒ½çš„ä»£ç å—æ ‡è®°
        if content.startswith("```json"):
            content = content[7:]
        if content.startswith("```"):
            content = content[3:]
        if content.endswith("```"):
            content = content[:-3]
        content = content.strip()
        
        return json.loads(content)
    except json.JSONDecodeError as e:
        logger.error(f"âš ï¸  è§£æ LLM å“åº”å¤±è´¥: {e}")
        logger.debug(f"åŸå§‹å“åº”: {content}")
        return {
            "action": "final_answer",
            "answer": f"æŠ±æ­‰ï¼Œæˆ‘æ— æ³•æ­£ç¡®è§£æå“åº”ã€‚åŸå§‹å†…å®¹ï¼š{content}"
        }


async def main():
    """ä¸»å‡½æ•° - AI Agent æ¨¡å¼"""
    logger.info("ğŸ¤– å¯åŠ¨ AI Agent æ¨¡å¼...")
    logger.info("=" * 60)
    
    # 1) è·å–å¯ç”¨å·¥å…·åˆ—è¡¨
    logger.info("ğŸ“‹ æ­£åœ¨è·å– MCP æœåŠ¡å™¨å·¥å…·åˆ—è¡¨...")
    tools = await get_available_tools()
    logger.info(f"âœ… å‘ç° {len(tools)} ä¸ªå¯ç”¨å·¥å…·:")
    for tool in tools:
        logger.info(f"   - {tool['name']}: {tool['description']}")
    
    tools_info = format_tools_for_llm(tools)
    
    # 2) ç”¨æˆ·æŸ¥è¯¢
    user_query = """è¯·å®Œæˆä»¥ä¸‹ä»»åŠ¡:
1. è·å–å½“å‰QDIIåŸºé‡‘çš„æº¢ä»·å¥—åˆ©å€™é€‰åˆ—è¡¨
2. åˆ†æè¿™äº›åŸºé‡‘çš„æº¢ä»·æƒ…å†µ
3. å°†åˆ†æç»“æœé€šè¿‡å¾®ä¿¡é€šçŸ¥å‘é€ç»™æˆ‘

æ³¨æ„:å¿…é¡»å®Œæˆæ‰€æœ‰3ä¸ªæ­¥éª¤,ä¸èƒ½é—æ¼å‘é€å¾®ä¿¡é€šçŸ¥ã€‚"""
    logger.info(f"ğŸ’¬ ç”¨æˆ·æŸ¥è¯¢: {user_query}")
    logger.info("=" * 60)
    
    # 3) AI Agent å¾ªç¯
    conversation_history = []
    max_iterations = 5  # æœ€å¤šè¿­ä»£5æ¬¡ï¼Œé¿å…æ— é™å¾ªç¯
    iteration = 0
    
    while iteration < max_iterations:
        iteration += 1
        logger.info(f"ğŸ”„ ç¬¬ {iteration} è½®æ€è€ƒ...")
        
        # è®© LLM å†³å®šä¸‹ä¸€æ­¥è¡ŒåŠ¨
        decision = ask_deepseek_with_tools(
            user_query if iteration == 1 else "è¯·æ ¹æ®å·²è·å¾—çš„ä¿¡æ¯,ç»§ç»­æ‰§è¡Œä¸‹ä¸€ä¸ªæœªå®Œæˆçš„ä»»åŠ¡æ­¥éª¤ã€‚å¦‚æœæ‰€æœ‰æ­¥éª¤éƒ½å·²å®Œæˆ,è¯·ç»™å‡ºæœ€ç»ˆç­”æ¡ˆã€‚",
            tools_info,
            conversation_history
        )
        
        logger.info(f"ğŸ’¡ LLM å†³ç­–: {decision.get('action')}")
        
        if decision.get("action") == "tool_call":
            # è°ƒç”¨å·¥å…·
            tool_name = decision.get("tool_name")
            arguments = decision.get("arguments", {})
            reason = decision.get("reason", "")
            
            logger.info(f"ğŸ”§ è°ƒç”¨å·¥å…·: {tool_name}")
            logger.info(f"   å‚æ•°: {json.dumps(arguments, ensure_ascii=False)}")
            logger.info(f"   åŸå› : {reason}")
            
            try:
                result = await call_mcp_tool(tool_name, arguments)
                logger.info(f"âœ… å·¥å…·è°ƒç”¨æˆåŠŸ")
                
                # å°†å·¥å…·è°ƒç”¨ç»“æœæ·»åŠ åˆ°å¯¹è¯å†å²
                conversation_history.append({
                    "role": "assistant",
                    "content": json.dumps(decision, ensure_ascii=False)
                })
                conversation_history.append({
                    "role": "user",
                    "content": f"å·¥å…· {tool_name} æ‰§è¡Œç»“æœ:\n{json.dumps(result, ensure_ascii=False, indent=2)}"
                })
                
            except Exception as e:
                logger.error(f"âŒ å·¥å…·è°ƒç”¨å¤±è´¥: {e}")
                conversation_history.append({
                    "role": "user",
                    "content": f"å·¥å…·è°ƒç”¨å¤±è´¥: {str(e)}"
                })
        
        elif decision.get("action") == "final_answer":
            # ç»™å‡ºæœ€ç»ˆç­”æ¡ˆ
            answer = decision.get("answer", "")
            logger.info("\n" + "=" * 60)
            logger.info("ğŸ“Š æœ€ç»ˆåˆ†ææŠ¥å‘Š:")
            logger.info("=" * 60)
            logger.info(answer)
            logger.info("=" * 60)
            break
        
        else:
            logger.warning(f"âš ï¸  æœªçŸ¥çš„ action: {decision.get('action')}")
            break
    
    if iteration >= max_iterations:
        logger.warning("âš ï¸  è¾¾åˆ°æœ€å¤§è¿­ä»£æ¬¡æ•°ï¼Œç»ˆæ­¢æ‰§è¡Œ")


if __name__ == "__main__":
    asyncio.run(main())